{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Similar Question finder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SEEKER\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "import numpy as np\n",
    "from gensim.models.keyedvectors import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filename):\n",
    "    data = []\n",
    "    # open the file and load the training questions with positives and\n",
    "    # negatives\n",
    "    with open(filename, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            data.append(line.strip().split('\\t'))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_data(filename='data/validation.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_candidates(question, candidates, embeddings, dim=300):\n",
    "    # get embeddings for question \n",
    "    question_embed = question_embedding(question, word_embeddings)\n",
    "    # get embeddings for candidates\n",
    "    candidates_embed = np.array([question_embedding(candidate, word_embeddings) \n",
    "                          for candidate in candidates])\n",
    "    # compute cosine similarity\n",
    "    candidates_sim = cosine_similarity(question_embed.reshape(1, -1), candidates_embed.reshape(1,-1))[0]\n",
    "    # make a tuple pair(sim, candidate question index)\n",
    "    candidates_ques_sim = [(sim, i) for i, sim in enumerate(candidates_sim)]\n",
    "    # sort the list\n",
    "    candidates_ques_sim = sorted(candidates_ques_sim)\n",
    "    final_candidates_ranking = [(index, candidates[index]) for _,index in candidates_ques_sim]\n",
    "    return final_candidates_ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_embeddings = KeyedVectors.load_word2vec_format(\n",
    "                    'embeddings/GoogleNews-vectors-negative300.bin',\n",
    "                    binary=True, limit=500000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "[('queen', 0.7118192911148071), ('monarch', 0.6189674139022827), ('princess', 0.5902431011199951), ('crown_prince', 0.5499460697174072), ('prince', 0.5377321243286133), ('kings', 0.5236844420433044), ('queens', 0.518113374710083), ('sultan', 0.5098593235015869), ('monarchy', 0.5087411999702454), ('royal_palace', 0.5087165832519531)]\n"
     ]
    }
   ],
   "source": [
    "# sanity checking\n",
    "print('neural' in word_embeddings)\n",
    "print(word_embeddings.most_similar(positive=['woman', 'king'], negative=['man']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_embeddings['apple'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for representing the question as vector of embeddings for \n",
    "# known words in question. We take the mean of all the embeddings for the \n",
    "# words of the question\n",
    "def question_embedding(question, word_embeddings):\n",
    "    # dimension of embedding = 300, since we are using the google's 300d embeddings\n",
    "    dim = 300\n",
    "    # tokenize the question \n",
    "    question = question.split()\n",
    "    \n",
    "    question_vector = [word_embeddings[word] for word in question if word in word_embeddings]\n",
    "    \n",
    "    # return if there is atleast one word known to the pretrained embedding\n",
    "    if len(question_vector) == 0:\n",
    "        return np.zeros(dim) \n",
    "    \n",
    "    # take the mean along the axis = 0(along each column).\n",
    "    # since each embedding is (300,1)\n",
    "    # so all of them will have shape (no. of words, 300)\n",
    "    question_vector = np.array(question_vector)\n",
    "    question_vector = np.mean(question_vector, axis=0)\n",
    "    \n",
    "    return question_vector "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <u>Evaluation metrics\n",
    "We will use two evaluation metrics for this task.\n",
    "    \n",
    "***1. Hits@k***\n",
    "\n",
    "***2. DCG@k***\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    ranks: list of ranks for each duplicate\n",
    "    k: (int) stating the window size to scan\n",
    "'''\n",
    "def hits_k(k, ranks):\n",
    "    hit_score = np.array(ranks) <= k\n",
    "    hit_score = hit_score.mean()\n",
    "    return hit_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    ranks: list of ranks for each duplicate\n",
    "    k: (int) stating the window size to scan\n",
    "'''\n",
    "def dcg_k(k, ranks):\n",
    "    dcg_score = np.array(ranks) <= k\n",
    "    dcg_score = dcg_score/np.log2(1 + np.array(ranks))\n",
    "    dcg_score = dcg_score.mean()\n",
    "    \n",
    "    return dcg_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
