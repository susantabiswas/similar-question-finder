{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Similar Question finder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import numpy as np\n",
    "from gensim.models.keyedvectors import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_embeddings = KeyedVectors.load_word2vec_format(\n",
    "                    'embeddings/GoogleNews-vectors-negative300.bin',\n",
    "                    binary=True, limit=500000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "[('queen', 0.7118192911148071), ('monarch', 0.6189674139022827), ('princess', 0.5902431011199951), ('crown_prince', 0.5499460697174072), ('prince', 0.5377321243286133), ('kings', 0.5236844420433044), ('queens', 0.518113374710083), ('sultan', 0.5098593235015869), ('monarchy', 0.5087411999702454), ('royal_palace', 0.5087165832519531)]\n"
     ]
    }
   ],
   "source": [
    "# sanity checking\n",
    "print('neural' in word_embeddings)\n",
    "print(word_embeddings.most_similar(positive=['woman', 'king'], negative=['man']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_embeddings['apple'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for representing the question as vector of embeddings for \n",
    "# known words in question. We take the mean of all the embeddings for the \n",
    "# words of the question\n",
    "def question_embedding(question, word_embeddings):\n",
    "    # dimension of embedding = 300, since we are using the google's 300d embeddings\n",
    "    dim = 300\n",
    "    # tokenize the question \n",
    "    question = question.split()\n",
    "    \n",
    "    question_vector = [word_embeddings[word] for word in question if word in word_embeddings]\n",
    "    \n",
    "    # return if there is atleast one word known to the pretrained embedding\n",
    "    if len(question_vector) == 0:\n",
    "        return np.zeros(dim) \n",
    "    \n",
    "    # take the mean along the axis = 0(along each column).\n",
    "    # since each embedding is (300,1)\n",
    "    # so all of them will have shape (no. of words, 300)\n",
    "    question_vector = np.array(question_vector)\n",
    "    question_vector = np.mean(question_vector, axis=0)\n",
    "    \n",
    "    return question_vector "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
