{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Similar Question finder\n",
    "Find similar questions using word embeddings. Here we use Google's 300 dimensional word embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SEEKER\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\SEEKER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "import numpy as np\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    for preprocessing text\n",
    "    text(string)\n",
    "'''\n",
    "def preprocess_text(text):\n",
    "    STOPWORDS = set(stopwords.words('english'))\n",
    "    # convert to lowercase\n",
    "    text = text.lower()\n",
    "    # replace whitespaces and punctuations\n",
    "    text = re.sub('[/(){}\\[\\]\\|@,;]', ' ', text)\n",
    "    text = re.sub('[^0-9a-z #+_]', '', text)\n",
    "    text = ' '.join(word for word in text.split() if word not in STOPWORDS)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    For loading the data files\n",
    "    filename(string): filename with full address\n",
    "'''\n",
    "def load_data(filename):\n",
    "    data = []\n",
    "    # open the file and load the training questions with positives and\n",
    "    # negatives\n",
    "    with open(filename, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            data.append(line.strip().split('\\t'))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    For preprocessing the entire dataset\n",
    "    data(list of list): list of questions and its candidate duplicates\n",
    "'''\n",
    "def preprocess_data(data):\n",
    "    data_processed = []\n",
    "    for i, line in tqdm(enumerate(data)):\n",
    "        data_processed.append([])\n",
    "        for j, l in enumerate(line):\n",
    "            data_processed[i].append(preprocess_text(l))\n",
    "            \n",
    "    return data_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "train_data = data = load_data(filename='data/train.tsv')\n",
    "data = load_data(filename='data/validation.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9680it [45:18,  3.56it/s]"
     ]
    }
   ],
   "source": [
    "# preprocess the data\n",
    "data = preprocess_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    For ranking the duplicate question candidates\n",
    "    question(string): original question\n",
    "    candidates(list of list): list of duplicate candidates for each question\n",
    "    embeddings(numpy array): embeddings \n",
    "'''\n",
    "def rank_duplicate_candidates(question, candidates, embeddings, dim=300):\n",
    "    # get embeddings for question \n",
    "    question_embed = question_embedding(question, word_embeddings, dim=dim)\n",
    "    # get embeddings for candidates\n",
    "    candidates_embed = np.array([question_embedding(candidate, word_embeddings) \n",
    "                          for candidate in candidates])\n",
    "    # compute cosine similarity\n",
    "    candidates_sim = cosine_similarity(question_embed.reshape(1,-1), candidates_embed)[0]\n",
    "    # make a tuple pair(sim, candidate question index)\n",
    "    candidates_ques_sim = [(sim, i) for i, sim in enumerate(candidates_sim)]\n",
    "    # sort the list in descending order\n",
    "    candidates_ques_sim = sorted(candidates_ques_sim, reverse=True)\n",
    "    final_candidates_ranking = [(index, candidates[index]) for _,index in candidates_ques_sim]\n",
    "    \n",
    "    return final_candidates_ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load google word embeddings\n",
    "word_embeddings = KeyedVectors.load_word2vec_format(\n",
    "                    'embeddings/GoogleNews-vectors-negative300.bin',\n",
    "                    binary=True, limit=500000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "[('queen', 0.7118192911148071), ('monarch', 0.6189674139022827), ('princess', 0.5902431011199951), ('crown_prince', 0.5499460697174072), ('prince', 0.5377321243286133), ('kings', 0.5236844420433044), ('queens', 0.518113374710083), ('sultan', 0.5098593235015869), ('monarchy', 0.5087411999702454), ('royal_palace', 0.5087165832519531)]\n"
     ]
    }
   ],
   "source": [
    "# sanity checking\n",
    "print('neural' in word_embeddings)\n",
    "print(word_embeddings.most_similar(positive=['woman', 'king'], negative=['man']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_embeddings['apple'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' For representing the question as vector of embeddings for \n",
    "    known words in question. We take the mean of all the embeddings for the \n",
    "    words of the question.\n",
    "    \n",
    "    question(string): input question\n",
    "'''\n",
    "def question_embedding(question, word_embeddings, dim=300):\n",
    "    # tokenize the question \n",
    "    question = question.split()\n",
    "    \n",
    "    question_vector = [word_embeddings[word] for word in question if word in word_embeddings]\n",
    "    \n",
    "    # return if there is atleast one word known to the pretrained embedding\n",
    "    if len(question_vector) == 0:\n",
    "        return np.zeros(dim) \n",
    "    \n",
    "    # take the mean along the axis = 0(along each column).\n",
    "    # since each embedding is (300,1)\n",
    "    # so all of them will have shape (no. of words, 300)\n",
    "    question_vector = np.array(question_vector)\n",
    "    question_vector = np.mean(question_vector, axis=0)\n",
    "    \n",
    "    return question_vector "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <u>Evaluation metrics\n",
    "We will use two evaluation metrics for checking the quality of the predicting the duplicate.\n",
    "    \n",
    "***1. Hits@k***\n",
    "<br>It sees how many times the correct duplicate candiate lie within the first k entries.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\text{Hits@K} = \\frac{1}{N}\\sum_{i=1}^N \\, [dup_i \\in topK(q_i)]$$\n",
    "\n",
    "$q_i:$ i-th query <br>$dup_i:$ Correct duplicate for this question<br> $topK(q_i):$ Top K ranked duplicate candidates by the model<br>\n",
    "$dup_i \\in topK(q_i)$ equals 1 if the condition is true and 0 otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    ranks: list of ranks for each duplicate\n",
    "    k: (int) stating the window size to scan\n",
    "'''\n",
    "def hits_k(k, ranks):\n",
    "    hit_score = np.array(ranks) <= k\n",
    "    hit_score = hit_score.mean()\n",
    "    return hit_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "***2. DCG@k***\n",
    "If the position of the correct duplicate is higher then the score will be higher.\n",
    "\n",
    "$$ \\text{DCG@K} = \\frac{1}{N} \\sum_{i=1}^N\\frac{1}{\\log_2(1+rank_{dup_i})}\\cdot[rank_{dup_i} \\le K] $$\n",
    "\n",
    "$rank_{dup_i}:$ Position of the correct duplicate in the sorted list of candidates for the current query $q_i$ question. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    ranks: list of ranks for each duplicate\n",
    "    k: (int) stating the window size to scan\n",
    "'''\n",
    "def dcg_k(k, ranks):\n",
    "    dcg_score = np.array(ranks) <= k\n",
    "    dcg_score = dcg_score/np.log2(1 + np.array(ranks))\n",
    "    dcg_score = dcg_score.mean()\n",
    "    \n",
    "    return dcg_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for storing the ranks of the duplicates\n",
    "duplicate_rank = []\n",
    "\n",
    "for line in data_processed:\n",
    "    # get the question and duplicate candidates\n",
    "    question, *candidates = line\n",
    "    # get the rankings for the candidates\n",
    "    candidate_rankings = rank_duplicate_candidates(question, candidates, word_embeddings)\n",
    "    # store the index of the correct duplicate in rankings\n",
    "    for rank,(index,_) in enumerate(candidate_rankings):\n",
    "        if index == 0:\n",
    "            duplicate_rank.append(rank+1)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    K|    DCG Score   |    Hits Score\n",
      "    1|    0.2944      |    0.2944\n",
      "    5|    0.3706      |    0.4374\n",
      "   10|    0.3873      |    0.4890\n",
      "   50|    0.4122      |    0.6009\n",
      "  100|    0.4212      |    0.6562\n",
      "  200|    0.4297      |    0.7172\n",
      "  500|    0.4433      |    0.8304\n",
      " 1000|    0.4610      |    1.0000\n"
     ]
    }
   ],
   "source": [
    "# check scores for different k values\n",
    "print(\"    K|    DCG Score   |    Hits Score\")\n",
    "for k in [1, 5, 10, 50, 100, 200, 500, 1000]:\n",
    "    print(\"%5d|    %.4f      |    %.4f\" % \n",
    "          (k, dcg_k(k, duplicate_rank), hits_k(k, duplicate_rank)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
